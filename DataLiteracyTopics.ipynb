{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Topic Modelling of DL Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "import bleach\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ConditionalFreqDist, FreqDist\n",
    "import nltk\n",
    "import gexf as g\n",
    "import collections\n",
    "import os.path\n",
    "\n",
    "# Fix invalid display error\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening - Carlson et al. - 2011 - Determining Data Information Literacy Needs A Study of Students and Research Faculty.pdf.txt\n",
      "opening - Fonticiaro, Oehrli - 2016 - Why data literacy matters.pdf.txt\n",
      "opening - blog - sod - defining dl.txt\n",
      "opening - Teal et al. - 2015 - Data Carpentry Workshops to Increase Data Literacy for Researchers.pdf.txt\n",
      "opening - Determining Data Information Literacy Needs- A Study of Students.pdf.txt\n",
      "opening - Erwin - 2015 - Data Literacy Real-World Learning Through Problem-Solving With Data Sets.pdf.txt\n",
      "opening - Data-Pop Alliance - 2015 - Beyond Data Literacy Reinventing Community Engagement and Empowerment in the Age of Data.pdf.txt\n",
      "opening - blog- Advancing Data Literacy.txt\n",
      "opening - Martin - 2014 - What Is Data Literacy.pdf.txt\n",
      "opening - Mandinach, Gummer - 2013 - A Systemic View of Implementing Data Literacy in Educator Preparation.pdf.txt\n",
      "opening - Koltay - 2015 - Data literacy in search of a name and identity.pdf.txt\n",
      "opening - Anderson et al. - 2015 - Ethical and Appropriate Data Use Requires Data Literacy.pdf.txt\n",
      "opening - Federer, Lu, Joubert - 2016 - Data literacy training needs of biomedical researchers.pdf.txt\n"
     ]
    }
   ],
   "source": [
    "indirname = \"/home/paulus/docs/datalit/\"\n",
    "paperlist = []\n",
    "paperdict = dict()\n",
    "   \n",
    "for fn in os.listdir(indirname ):\n",
    "    if fn.endswith(\".txt\"):\n",
    "        print \"opening - \" + fn\n",
    "        hdl = open(indirname + fn)\n",
    "        txt = hdl.read()\n",
    "        paperlist.append(txt)\n",
    "        \n",
    "        index_of_dot = fn.index('.')\n",
    "        fns = fn[:index_of_dot]\n",
    "        paperdict[fns]=dict()\n",
    "        paperdict[fns][\"text\"] = txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist.extend([u'',u'data',u'literacy',u'data,', u'dil', u'training',\n",
    "                 u'information',u'research',u'faculty',u'big',u'used',u'work',\n",
    "                 u'researchers', u'student',u'education',u'educators',u'skills',\n",
    "                 u'librarians',u'learning',u'ability', u'understanding',\n",
    "                 u'management',u'using',u'knowledge',u'know', u'course',u'social',u'different',\n",
    "                 u'also',u'al.',u'al.,',\n",
    "                 u'et',u'no.',u'literacy.',u'students',u'data.',u'june',u'association\\nmay',\n",
    "                 u'literacy',u'michigan',u'literacy,',u'de',u'data-related',\n",
    "                 u\"don't\",u\"isn't\",u'want',u'get',u'best',u'things',u'‘Hi’',u'it’s',u\"don’t\",\n",
    "                 u'even',u\"we're\",u'like',u'&',u'may',u'must', u'j.',u'e.',u'data-driven',\n",
    "                 u'use', u'nih',u'j,', u'need', u'new',u'needs', u'acrl',\n",
    "                 u'would',u'one',u'think',u'might',u'could',u'it\\'s',u'us',u'don\\'t',u'i\\'m'])\n",
    "texts = [[word for word in paper.lower().split(\" \") if word not in stoplist]\n",
    "for paper in paperlist]\n",
    "\n",
    "# remove words that appear only once\n",
    "all_tokens = sum(texts, [])\n",
    "gensim.utils.lemmatize(document, allowed_tags=re.compile('(NN|VB|JJ|RB)'))\n",
    "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "texts = [[word for word in text if word not in tokens_once]\n",
    "         for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('../output/dl.dict') # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('../output/dl.mm', corpus) # store to disk, for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=8, onepass=False)\n",
    "#lsi.print_topics(200)\n",
    "\n",
    "lda = models.LdaModel(corpus, id2word=dictionary,num_topics=6, passes=5,  iterations=5)\n",
    "lda.print_topics(num_topics=3, num_words=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK Fred!!\n"
     ]
    }
   ],
   "source": [
    "def is_useful(tag):\n",
    "    return tag.lower() in ['nn','nns','np','nnp','vb','vbj','vbn','vbg','vbd','vbp','vbz'] \n",
    "\n",
    "sent_tokenizer=nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "stoplist = stopwords.words('english')\n",
    "theData = collections.Counter()\n",
    "\n",
    "for name in paperdict.keys():\n",
    "    try:\n",
    "        paperdict[name][\"content\"] = collections.Counter()\n",
    "        paper = paperdict[name][\"text\"].decode('utf-8')\n",
    "        sentences = sent_tokenizer.tokenize(paper)\n",
    "        for sentence in sentences:\n",
    "            content =  nltk.word_tokenize(sentence)\n",
    "            tagged_content = nltk.pos_tag(content)\n",
    "\n",
    "            for (index, tagtuple) in enumerate(tagged_content):\n",
    "                    (token, tag) = tagtuple\n",
    "                    token = token.lower()\n",
    "                    if token not in stoplist and is_useful(tag) and len(token)>2:\n",
    "                            theData[token] +=1\n",
    "                            paperdict[name][\"content\"][token]+=1\n",
    "    except UnicodeDecodeError as e:\n",
    "            print \"paper didn't work!\"\n",
    "\n",
    "\n",
    "print \"OK Fred!!\"\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'data', 2474), (u'literacy', 760), (u'information', 440), (u'students', 428), (u'research', 312), (u'use', 233), (u'skills', 198), (u'need', 190), (u'researchers', 179), (u'faculty', 161), (u'student', 139), (u'education', 139), (u'management', 138), (u'analysis', 127), (u'work', 118), (u'needs', 116), (u'knowledge', 113), (u'training', 109), (u'course', 103), (u'using', 100), (u'understanding', 98), (u'librarians', 93), (u'learning', 91), (u'know', 90), (u'development', 89), (u'standards', 80), (u'used', 80), (u'tools', 78), (u'ability', 77), (u'metadata', 76), (u'understand', 76), (u'science', 73), (u'practices', 73), (u'project', 70), (u'people', 68), (u'practice', 68), (u'program', 65), (u'community', 65), (u'needed', 64), (u'make', 63), (u'time', 62), (u'making', 62), (u'set', 61), (u'part', 60), (u'libraries', 60), (u'educators', 59), (u'university', 59), (u'quality', 58), (u'provide', 57), (u'media', 57), (u'access', 57), (u'programs', 56), (u'dil', 56), (u'sharing', 56), (u'curation', 56), (u'assessment', 56), (u'literate', 56), (u'questions', 55), (u'issues', 55), (u'including', 55), (u'develop', 54), (u'process', 54), (u'schools', 53), (u'inclusion', 53), (u'al.', 53), (u'visualization', 52), (u'way', 52), (u'carpentry', 52), (u'study', 51), (u'support', 51), (u'sources', 50), (u'big', 49), (u'survey', 49), (u'sets', 49), (u'teachers', 48), (u'workshops', 48), (u'help', 48), (u'include', 48), (u'based', 48), (u'school', 47), (u'example', 47), (u'world', 47), (u'role', 46), (u'library', 46), (u'content', 45), (u'courses', 45), (u'instruction', 45), (u'software', 45), (u'graduate', 44), (u'revolution', 43), (u'curriculum', 43), (u'problems', 43), (u'importance', 43), (u'focus', 42), (u'documentation', 42), (u'preservation', 42), (u'authors', 42), (u'create', 42), (u'instructors', 42), (u'age', 42), (u'others', 42), (u'concepts', 41), (u'things', 41), (u'expertise', 41), (u'concept', 41), (u'developing', 41), (u'technology', 41), (u'interviews', 41), (u'statistics', 41), (u'lab', 40), (u'level', 40), (u'address', 40), (u'ways', 40), (u'developed', 40), (u'decision', 40), (u'lack', 38), (u'services', 38), (u'methods', 38), (u'results', 38), (u'approaches', 38), (u'acrl', 37), (u'become', 37), (u'approach', 36), (u'core', 36), (u'working', 36), (u'topics', 36), (u'technologies', 36), (u'design', 36), (u'experience', 36), (u'determine', 35), (u'definition', 35), (u'projects', 35), (u'existing', 35), (u'nature', 35), (u'order', 34), (u'report', 34), (u'field', 34), (u'systems', 34), (u'individuals', 34), (u'analyze', 34), (u'engage', 34), (u'mandinach', 33), (u'change', 33), (u'participants', 33), (u'formats', 33), (u'identify', 32), (u'policy', 32), (u'file', 32), (u'learn', 32), (u'purdue', 32)]\n"
     ]
    }
   ],
   "source": [
    "print theData.most_common(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'data', 155), (u'education', 61), (u'use', 52), (u'literacy', 52), (u'educators', 46), (u'schools', 41), (u'courses', 30), (u'al.', 29), (u'making', 27), (u'need', 27), (u'decision', 26), (u'development', 24), (u'mandinach', 23), (u'knowledge', 21), (u'systems', 20), (u'needs', 17), (u'practice', 17), (u'preparation', 17), (u'skills', 16), (u'teachers', 15), (u'organizations', 14), (u'policy', 14), (u'research', 14), (u'student', 14), (u'training', 13), (u'states', 13), (u'districts', 12), (u'decisions', 11), (u'standards', 11), (u'address', 11), (u'teacher', 11), (u'change', 11), (u'field', 11), (u'educator', 10), (u'state', 10), (u'practices', 10), (u'evidence', 10), (u'requirements', 9), (u'capacity', 9), (u'agencies', 9), (u'learning', 9), (u'understand', 9), (u'stakeholders', 9), (u'using', 9), (u'gummer', 9), (u'preservice', 9), (u'accreditation', 8), (u'love', 8), (u'inform', 8), (u'faculty', 8), (u'system', 8), (u'needed', 8), (u'programs', 8), (u'make', 8), (u'components', 8), (u'administrators', 8), (u'teaching', 7), (u'school', 7), (u'growing', 7), (u'process', 7), (u'course', 7), (u'duncan', 7), (u'integrate', 7), (u'licensure', 7), (u'article', 7), (u'assessment', 7), (u'requires', 7), (u'existing', 6), (u'opportunities', 6), (u'concepts', 6), (u'work', 6), (u'help', 6), (u'including', 6), (u'ccsso', 6), (u'part', 6), (u'roles', 6), (u'require', 6), (u'build', 6), (u'impact', 6), (u'candidates', 6), (u'respond', 6), (u'importance', 6), (u'slds', 6), (u'assessments', 6), (u'http', 6), (u'analysis', 6), (u'improvement', 6), (u'know', 6), (u'support', 6), (u'focus', 5), (u'issues', 5), (u'understanding', 5), (u'addressed', 5), (u'providers', 5), (u'information', 5), (u'educational', 5), (u'september', 5), (u'years', 5), (u'england', 5), (u'issue', 5), (u'integrated', 5), (u'emphasis', 5), (u'performance', 5), (u'means', 5), (u'policymakers', 5), (u'testing', 5), (u'approach', 5), (u'stakeholder', 5), (u'offerings', 5), (u'boudett', 5), (u'west', 5), (u'develop', 5), (u'survey', 5), (u'levels', 5), (u'univ', 5), (u'influence', 5), (u'students', 5), (u'lack', 4), (u'program', 4), (u'include', 4), (u'wayman', 4), (u'halverson', 4), (u'action', 4), (u'changes', 4), (u'licensing', 4), (u'provide', 4), (u'occur', 4), (u'happen', 4), (u'discuss', 4), (u'funding', 4), (u'base', 4), (u'researcher', 4), (u'improving', 4), (u'differ', 4), (u'play', 4), (u'multiple', 4), (u'achievement', 4), (u'sources', 4), (u'national', 4), (u'literate', 4), (u'nature', 4), (u'improve', 4), (u'meeting', 4), (u'look', 4), (u'developing', 4), (u'experts', 4), (u'technology', 4), (u'identify', 4), (u'thinking', 4), (u'instruction', 4)]\n"
     ]
    }
   ],
   "source": [
    "print paperdict[paperdict.keys()[5]]['content'].most_common(150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
